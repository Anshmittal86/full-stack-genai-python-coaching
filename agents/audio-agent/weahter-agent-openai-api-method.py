import json
import requests

from dotenv import load_dotenv
from openai import OpenAI
from pathlib import Path
from playsound import playsound

load_dotenv()

client = OpenAI()

def get_weather(city: str):
    print("ðŸ”¨ Tool Called: get_weather", city)
    
    url = f"https://wttr.in/{city}?format=%C+%t"
    response = requests.get(url)

    if response.status_code == 200:
        return f"The current weather of {city} is {response.text}."
    return "Something went wrong"

# 1. Define a list of callable tools for the model
tools = [
    {
        "type": "function",
        "name": "get_weather",
        "description": "Takes a city name as an input and returns the current weather for the city",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {
                    "type": "string",
                    "description": "The city name which weather we want to know.",
                },
            },
            "required": ["city"],
        },
    },
]

user_query = input("ðŸ‘¨: ")

input_list = [
    {"role": "user", "content": user_query}
]

# 2. Prompt the model with tools defined
response = client.responses.create(
    model="gpt-4o-mini",
    tools=tools,
    input=input_list,
)

# Save function call outputs for subsequent requests
input_list += response.output

for item in response.output:
    if item.type == "function_call":
        if item.name == "get_weather":
            # 3. Execute the function logic for get_horoscope
            weather_response = get_weather(json.loads(item.arguments))
            
            # 4. Provide function call results to the model
            input_list.append({
                "type": "function_call_output",
                "call_id": item.call_id,
                "output": json.dumps({
                  "weather_response": weather_response
                })
            })

response = client.responses.create(
    model="gpt-4o-mini",
    instructions="Respond only with a get_weather generated by a tool.",
    tools=tools,
    input=input_list,
)

# 5. The model should be able to give a response!
print("Final output:")
response.model_dump_json(indent=2)
print("\n" + response.output_text)

speech_file_path = Path(__file__).parent / "speech.mp3"
with client.audio.speech.with_streaming_response.create(
  model="gpt-4o-mini-tts",
  voice="alloy",
  input=response.output_text
) as response:
  response.stream_to_file(speech_file_path)

playsound('./speech.mp3')